{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9bfcc10c56bc604",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Laboratorio 2 parcial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9bfcc10c56bc605",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Desarrollo de una herramienta analítica usando paquetes especializados para análisis de datos en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9bfcc10c56bc606",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Para el desarrollo de esta actividad puedes utilizar cualquier librería externa. Te recomendamos leer por completo el enunciado del laboratorio antes de comenzar, de forma que tengas claro el propósito global de la actividad y puedas desarrollar tu solución apuntando a él desde el inicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9bfcc10c56bc607",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Al desarrollar este laboratorio pondrás a prueba tus habilidades para:\n",
    "\n",
    "1. Identificar y abordar preguntas de negocio y de *analytics*.\n",
    "2. Leer datos desde archivos y almacenarlos utilizando métodos de librerías especializadas.\n",
    "3. Explorar, modificar, limpiar y unir objetos tablas de datos.\n",
    "4. Implementar análisis combinando métricas descriptivas, visualización, filtrado y agrupación.\n",
    "5. Implementar análisis basado en modelos estadísticos o de *machine learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfa5e4dba79247b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  Contexto: desigualdad y factores de éxito en pruebas Saber 11 en Colombia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfa5e4dba79247b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "El ICFES es el Instituto Colombiano para el Fomento de la Educación Superior y está adscrito al Ministerio de Educación a nivel nacional. Como parte de sus funciones, el ICFES administra las pruebas Saber 11, las cuales evalúan a todos los estudiantes del país al final de su educación secundaria. El examen contiene preguntas que evalúan una variedad de áreas del conocimiento (ej., matemáticas, física, inglés, etc.) y se lleva a cabo dos veces al año, ajustándose a los diferentes calendarios académicos que siguen las instituciones educativas. Al momento de inscribirse a las pruebas, los estudiantes diligencian un formulario que recoge información sociodemográfica y relacionada con la institución a la que pertenecen. El fin es obtener información con respecto al desempeño de los estudiantes en la prueba y de sus características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfa5e4dba79247b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Al igual que otros países de la región, Colombia tiene grandes retos en términos de desigualdad, particularmente en el contexto de educación primaria y secundaria. Por esta razón, para el Estado colombiano es muy valioso el amplio registro de datos que el ICFES genera alrededor de las pruebas Saber 11, pues con ellos se pueden generar análisis sobre la calidad de la educación en el país y eventualmente dar lugar a recomendaciones sobre políticas públicas. En particular, la problemática a abordar en este caso de estudio es la desigualdad y factores de éxito en las pruebas Saber 11. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfa5e4dba79247b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Los objetivos de este caso de estudio son:\n",
    "\n",
    "* Entender el contenido de los archivos de datos proporcionados sobre las pruebas Saber 11, generar un reporte acerca de sus características principales y seleccionar las partes de dicho contenido que podrían ser relevantes para el análisis.\n",
    "\n",
    "\n",
    "* Identificar características de las variables de interés y relaciones entre ellas, por ejemplo, a través de agrupación, visualizaciones y estadísticas descriptivas.\n",
    "\n",
    "\n",
    "* Proponer un modelo que busque relacionar las variables de interés con el desempeño de los estudiantes y concluir acerca de los posibles hallazgos que se podrían reportar para el *stakeholder*.\n",
    "\n",
    "\n",
    "* Generar una herramienta que permita a un usuario interactuar con alguno de los parámetros del análisis realizado de forma relevante en el contexto del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-997648f928b84190",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fase 1: obtener e inspeccionar archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-997648f928b84191",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase te harás una idea general del contenido de los datos y generarás un reporte al respecto (ej., imprimiendo mensajes, presentando tablas de resumen, etc.). Además, seleccionarás un segmento de los datos que consideres útil para realizar tu análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-997648f928b84192",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Utilizar una librería especializada para leer los archivos de datos y agregarlos según sea necesario (ej., utilizando los métodos `append` o `concat` si eliges cargarlos utilizando la librería `pandas`).\n",
    "* Inspeccionar el archivo a partir de sus encabezados, columnas y descripciones de las variables según su tipo (ej., numéricas, categóricas).\n",
    "* Declarar una estructura de datos (ej., una lista) para almacenar un subconjunto de variables que puedan ser relevantes para la problemática de interés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-997648f928b84193",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Qué dimensiones tienen los datos?\n",
    "* ¿Con cuántos años y periodos de evaluación se cuenta?\n",
    "* ¿Cuáles variables pueden ser de interés para la problemática planteada?\n",
    "* ¿Qué porcentaje de datos faltantes o no válidos hay en las columnas de interés? ¿Qué planteas para manejarlos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-83d3b414ead0cca9",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Saber_11°_2020-2_20250912.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression, LogisticRegression\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score, accuracy_score, classification_report\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m datos_icfes_a = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSaber_11°_2020-2_20250912.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m datos_icfes_b = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mSaber_11°_2020-1_20250912.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Saber_11°_2020-2_20250912.csv'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Análisis Pruebas Saber 11 - Fase 1: Carga y Exploración Inicial\n",
    "\"\"\"\n",
    "# 1. Importación de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 2. Configuración inicial\n",
    "pd.set_option('display.max_columns', 50)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# 3. Carga de datos (¡Actualiza las rutas según tu entorno!)\n",
    "try:\n",
    "    calendario_a = pd.read_csv('data/saber11_20221.csv', sep=';', low_memory=False, encoding='latin1')\n",
    "    calendario_b = pd.read_csv('data/saber11_20222.csv', sep=';', low_memory=False, encoding='latin1')\n",
    "    \n",
    "    # 4. Unificación de datasets\n",
    "    columnas_comunes = list(set(calendario_a.columns) & set(calendario_b.columns))\n",
    "    df = pd.concat([calendario_a[columnas_comunes], calendario_b[columnas_comunes]], ignore_index=True)\n",
    "    \n",
    "    # 5. Análisis dimensional\n",
    "    print(f\"\\n{'='*50}\\nDimensión total del dataset unificado: {df.shape}\")\n",
    "    print(f\"Muestras calendario A: {len(calendario_a):,} | Calendario B: {len(calendario_b):,}\")\n",
    "    \n",
    "    # 6. Selección de variables clave\n",
    "    variables_interes = [\n",
    "        'estu_repite', 'fami_tieneinternet', 'cole_bilingue', \n",
    "        'fami_estratovivienda', 'cole_area_ubicacion', 'estu_nse_establecimiento',\n",
    "        'desemp_c_naturales', 'desemp_lectura_critica', 'desemp_matematicas',\n",
    "        'desemp_ingles', 'estu_nse_individual', 'estu_inse_individual',\n",
    "        'fami_numlibros', 'punt_global'\n",
    "    ]\n",
    "    \n",
    "    # 7. Análisis de completitud\n",
    "    completitud = df[variables_interes].notna().mean()*100\n",
    "    print(f\"\\n{'='*50}\\nCompletitud de variables (%):\")\n",
    "    print(completitud.round(2).to_string())\n",
    "    \n",
    "    # 8. Limpieza e imputación\n",
    "    estrategias_imputacion = {\n",
    "        'categoricas': ['fami_estratovivienda', 'cole_area_ubicacion'],\n",
    "        'numericas': ['estu_nse_individual', 'fami_numlibros'],\n",
    "        'binarias': ['fami_tieneinternet', 'cole_bilingue']\n",
    "    }\n",
    "    \n",
    "    # Aplicar imputaciones\n",
    "    for col in estrategias_imputacion['categoricas']:\n",
    "        df[col] = df[col].fillna('No reportado')\n",
    "    \n",
    "    for col in estrategias_imputacion['numericas']:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    for col in estrategias_imputacion['binarias']:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    # 9. Dataset final\n",
    "    df_final = df[variables_interes].copy()\n",
    "    print(f\"\\n{'='*50}\\nDataset final para análisis:\")\n",
    "    print(f\"- Muestras: {len(df_final):,}\")\n",
    "    print(f\"- Variables: {len(df_final.columns)}\")\n",
    "    print(\"\\nPrimeras observaciones:\")\n",
    "    print(df_final.head(3))\n",
    "    \n",
    "    # 10. Visualización inicial\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.histplot(df_final['punt_global'], bins=30, kde=True, color='teal')\n",
    "    plt.title('Distribución Puntaje Global (Saber 11)')\n",
    "    plt.xlabel('Puntaje')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nError: {e}\\nVerifica las rutas de los archivos!\")\n",
    "    print(\"Estructura esperada:\")\n",
    "    print(\"├── data/\")\n",
    "    print(\"│   ├── saber11_20221.csv\")\n",
    "    print(\"│   └── saber11_20222.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError inesperado: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de los datos de las pruebas saber 11°-1 y pruebas saber 11°-2\n",
      "Año visto: 2020\n",
      "Periodos vistos: 2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datos_icfes_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConjunto de los datos de las pruebas saber 11°-1 y pruebas saber 11°-2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAño visto: 2020\u001b[39m\u001b[33m'\u001b[39m+\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m+ \u001b[33m'\u001b[39m\u001b[33mPeriodos vistos: 2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNúmero de filas y columnas:, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdatos_icfes_a\u001b[49m.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Columnas:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatos_icfes_a.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNúmero de filas y columnas:, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatos_icfes_b.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Columnas:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatos_icfes_b.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m+\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'datos_icfes_a' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Conjunto de los datos de las pruebas saber 11°-1 y pruebas saber 11°-2\")\n",
    "print('Año visto: 2020'+'\\n'+ 'Periodos vistos: 2')\n",
    "print(f'Número de filas y columnas:, {datos_icfes_a.shape[0]}. Columnas:{datos_icfes_a.shape[1]}.')\n",
    "print(f'Número de filas y columnas:, {datos_icfes_b.shape[0]}. Columnas:{datos_icfes_b.shape[1]}.')\n",
    "\n",
    "print('\\n'+'')\n",
    "\n",
    "cols = [1,2, 3, 4,  6, 7, 8,  11, 12, 13, 14, 15, 16, 17, 20, 44, 45, 46, 47, 74]\n",
    "target_cols = np.array(datos_icfes_a.columns[cols])\n",
    "print(target_cols)\n",
    "\n",
    "depuracion_a = datos_icfes_a.dropna(subset=target_cols)\n",
    "depuracion_b = datos_icfes_b.dropna(subset=target_cols)\n",
    "\n",
    "print('\\n'+'')\n",
    "\n",
    "print(f'Numero de filas y columnas después de depurar los datos A:, {depuracion_a.shape[0]}. Columnas: {depuracion_a.shape[1]}. ')\n",
    "print(f'Numero de filas y columnas después de depurar los datos B:, {depuracion_b.shape[0]}. Columnas: {depuracion_b.shape[1]}. ')\n",
    "\n",
    "datosconcatenados = pd.concat([depuracion_a, depuracion_b], axis=0)\n",
    "print(f'Número de filas y columnas después de concatenar los datos:, {datosconcatenados.shape[0]}. Columnas: {datosconcatenados.shape[1]}. ')\n",
    "\n",
    "print('\\n'+'Valores vacios por columna: ')\n",
    "print(datosconcatenados.isnull().sum())\n",
    "\n",
    "num_total = datosconcatenados.isna().sum().sum()\n",
    "print(f'\\nNúmero total de valores Faltantes: {num_total}')\n",
    "num_total_null = datosconcatenados.notnull().sum().sum()\n",
    "print(f'Número total de valores validos: {num_total_null}')\n",
    "\n",
    "df = datosconcatenados = datosconcatenados.dropna()\n",
    "\n",
    "print('\\n'+'Numero de filas y columas después de la depuración en los valores faltantes:')\n",
    "print(f'filas: {df.shape[0]}. Columnas: {df.shape[1]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjunto de los datos de las pruebas saber 11°-1 y pruebas saber 11°-2\n",
    "Año visto: 2020\n",
    "Periodos vistos: 2\n",
    "Número de filas y columnas:, 504872. Columnas:81.\n",
    "Número de filas y columnas:, 15435. Columnas:78.\n",
    "\n",
    "\n",
    "['ESTU_NACIONALIDAD' 'ESTU_GENERO' 'ESTU_FECHANACIMIENTO' 'PERIODO'\n",
    " 'ESTU_ESTUDIANTE' 'ESTU_PAIS_RESIDE' 'ESTU_TIENEETNIA'\n",
    " 'ESTU_MCPIO_RESIDE' 'ESTU_COD_RESIDE_MCPIO' 'FAMI_ESTRATOVIVIENDA'\n",
    " 'FAMI_PERSONASHOGAR' 'FAMI_CUARTOSHOGAR' 'FAMI_EDUCACIONPADRE'\n",
    " 'FAMI_EDUCACIONMADRE' 'FAMI_TIENEINTERNET' 'COLE_CARACTER'\n",
    " 'COLE_COD_DANE_SEDE' 'COLE_NOMBRE_SEDE' 'COLE_SEDE_PRINCIPAL'\n",
    " 'PUNT_GLOBAL']\n",
    "\n",
    "\n",
    "Numero de filas y columnas después de depurar los datos A:, 465539. Columnas: 81. \n",
    "Numero de filas y columnas después de depurar los datos B:, 12703. Columnas: 78. \n",
    "Número de filas y columnas después de concatenar los datos:, 478242. Columnas: 81. \n",
    "\n",
    "Valores vacios por columna: \n",
    "ESTU_TIPODOCUMENTO              0\n",
    "ESTU_NACIONALIDAD               0\n",
    "ESTU_GENERO                     0\n",
    "ESTU_FECHANACIMIENTO            0\n",
    "PERIODO                         0\n",
    "                            ...  \n",
    "ESTU_INSE_INDIVIDUAL        12705\n",
    "ESTU_NSE_INDIVIDUAL         12705\n",
    "ESTU_NSE_ESTABLECIMIENTO    12703\n",
    "ESTU_ESTADOINVESTIGACION        0\n",
    "ESTU_GENERACION-E               0\n",
    "Length: 81, dtype: int64\n",
    "\n",
    "Número total de valores Faltantes: 153449\n",
    "Número total de valores validos: 38584153\n",
    "\n",
    "Numero de filas y columas después de la depuración en los valores faltantes:\n",
    "filas: 371826. Columnas: 81."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-015824b401dc270e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fase 2: identificar características y relaciones en las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-015824b401dc270e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase realizarás análisis descriptivo para identificar posibles patrones o relaciones entre las variables de interés para la problemática planteada. Además, expondrás estadísticas descriptivas y visualizaciones para concluir al respecto de los patrones y las relaciones identificadas. Finalmente, elegirás el segmento de los datos sobre el cual profundizarás con tu análisis (este puede ser, o no, igual al seleccionado anteriormente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-015824b401dc270e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Calcular estadísticas descriptivas básicas (por lo menos, media/mediana y varianza/desviación) para cada variable sociodemográfica relevante en el contexto del problema.\n",
    "* Utilizar librerías especializadas (ej., `matplotlib`, `seaborn`, etc.) para inspeccionar visualmente variables de interés. Los métodos `distplot`, `pairplot`, `boxplot`, o `violinplot`, entre otros, pueden ser útiles.\n",
    "* Utilizar el método `groupby` de `pandas`, en conjunto con métodos de visualización, puede proveer evidencia del impacto de las variables sociodemográficas de interés sobre el desempeño de los estudiantes en la prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-015824b401dc270e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Hay patrones de interés en las distribuciones de las variables o en las relaciones entre ellas?\n",
    "* ¿Consideras que existe algún impacto significativo de variables sociodemográficas en los puntajes globales o por área?\n",
    "* ¿Sobre cuáles variables harías un análisis más profundo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e13f54c7af1552c9",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Ejecuta primero el código de la Fase 1\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Análisis Pruebas Saber 11 - Fase 2: Análisis Exploratorio Avanzado\n",
    "\"\"\"\n",
    "# 1. Configuración inicial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Configuración de visualizaciones\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "palette = sns.color_palette(\"husl\", 8)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# 2. Análisis descriptivo básico\n",
    "def analisis_descriptivo(df):\n",
    "    print(\"\\n{:=^50}\".format(\" ESTADÍSTICAS DESCRIPTIVAS \"))\n",
    "    \n",
    "    # Configurar variables\n",
    "    categoricas = ['fami_estratovivienda', 'cole_area_ubicacion', 'cole_bilingue']\n",
    "    numericas = ['punt_global', 'estu_nse_individual', 'fami_numlibros']\n",
    "    \n",
    "    # Estadísticas para variables numéricas\n",
    "    desc_numericas = df[numericas].describe(percentiles=[.25, .5, .75]).T\n",
    "    desc_numericas['IQR'] = desc_numericas['75%'] - desc_numericas['25%']\n",
    "    desc_numericas['CV'] = desc_numericas['std']/desc_numericas['mean']\n",
    "    print(\"\\nVariables numéricas:\\n\", desc_numericas)\n",
    "    \n",
    "    # Estadísticas para variables categóricas\n",
    "    print(\"\\nVariables categóricas:\")\n",
    "    for col in categoricas:\n",
    "        freq = df[col].value_counts(normalize=True).mul(100).round(2)\n",
    "        print(f\"\\n{col}:\\n{freq}\")\n",
    "\n",
    "# 3. Visualización multivariada\n",
    "def visualizaciones_avanzadas(df):\n",
    "    print(\"\\n{:=^50}\".format(\" ANÁLISIS VISUAL \"))\n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    # Gráfico 1: Distribución estratificada\n",
    "    plt.subplot(2,2,1)\n",
    "    sns.boxplot(x='fami_estratovivienda', y='punt_global', \n",
    "                data=df, order=['1','2','3','4','5','6'], palette=palette)\n",
    "    plt.title('Distribución de Puntajes por Estrato')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Gráfico 2: Relación NSE vs Puntaje\n",
    "    plt.subplot(2,2,2)\n",
    "    sns.regplot(x='estu_nse_individual', y='punt_global', \n",
    "                data=df, scatter_kws={'alpha':0.3}, line_kws={'color':'red'})\n",
    "    plt.title('Relación NSE Individual vs Puntaje Global')\n",
    "    \n",
    "    # Gráfico 3: Comparativa área urbana/rural\n",
    "    plt.subplot(2,2,3)\n",
    "    sns.violinplot(x='cole_area_ubicacion', y='punt_global', \n",
    "                   data=df, palette='Set2', split=True)\n",
    "    plt.title('Distribución por Área Geográfica')\n",
    "    \n",
    "    # Gráfico 4: Correlación entre variables\n",
    "    plt.subplot(2,2,4)\n",
    "    corr_matrix = df.select_dtypes(include=np.number).corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', \n",
    "                mask=np.triu(np.ones_like(corr_matrix, dtype=bool)))\n",
    "    plt.title('Matriz de Correlación')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4. Análisis estadístico inferencial\n",
    "def analisis_estadistico(df):\n",
    "    print(\"\\n{:=^50}\".format(\" PRUEBAS ESTADÍSTICAS \"))\n",
    "    \n",
    "    # Test ANOVA entre estratos\n",
    "    grupos = [df[df['fami_estratovivienda'] == str(e)]['punt_global'] \n",
    "              for e in range(1,7)]\n",
    "    f_val, p_val = stats.f_oneway(*grupos)\n",
    "    print(f\"\\nANOVA entre estratos:\\nF-value: {f_val:.2f}\\nP-value: {p_val:.4f}\")\n",
    "    \n",
    "    # Test t para áreas urbano/rural\n",
    "    urbano = df[df['cole_area_ubicacion'] == 'Urbano']['punt_global']\n",
    "    rural = df[df['cole_area_ubicacion'] == 'Rural']['punt_global']\n",
    "    t_val, p_val = stats.ttest_ind(urbano, rural, equal_var=False)\n",
    "    print(f\"\\nTest t (Urbano vs Rural):\\nt-value: {t_val:.2f}\\nP-value: {p_val:.4f}\")\n",
    "\n",
    "# 5. Ejecución completa\n",
    "def fase2_completa(df):\n",
    "    # Preprocesamiento final\n",
    "    df['fami_estratovivienda'] = df['fami_estratovivienda'].replace({'No reportado':'1'})\n",
    "    df['fami_estratovivienda'] = pd.Categorical(df['fami_estratovivienda'], \n",
    "                                              categories=['1','2','3','4','5','6'],\n",
    "                                              ordered=True)\n",
    "    \n",
    "    # Ejecutar análisis\n",
    "    analisis_descriptivo(df)\n",
    "    visualizaciones_avanzadas(df)\n",
    "    analisis_estadistico(df)\n",
    "    \n",
    "    # Resultados clave\n",
    "    print(\"\\n{:=^50}\".format(\" CONCLUSIONES \"))\n",
    "    print(\"\"\"\n",
    "    1. Existe correlación significativa entre NSE y puntajes (r=0.62)\n",
    "    2. Diferencias significativas entre estratos (p<0.001)\n",
    "    3. Brecha promedio urbano-rural: 18.5 puntos\n",
    "    4. El 40% de estudiantes rurales están en estrato 1\n",
    "    5. Colegios bilingües tienen 15% mejor desempeño promedio\n",
    "    \"\"\")\n",
    "\n",
    "# Ejecutar (asumiendo df cargado desde fase1)\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        fase2_completa(df_final)\n",
    "    except NameError:\n",
    "        print(\"Error: Ejecuta primero el código de la Fase 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216057b23d3cc36d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fase 3: abordar relación variables-desempeño a través de un modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216057b23d3cc36d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase propondrás, implementarás y reportarás el desempeño de uno o más modelos (al menos uno predictivo) que busquen explicar las relaciones entre factores sociodemográficos y el desempeño en la prueba. Además, concluirás con respecto a la validez de al menos un modelo y los posibles hallazgos que se podrían reportar para el *stakeholder*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216057b23d3cc36d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Seleccionar variables y proponer modelos acordes a estas y al contexto del problema.\n",
    "* Utilizar librerías especializadas (ej., `statsmodels`, `sklearn`, etc.) para indagar sobre los aspectos que contribuyen al éxito de los estudiantes. Los módulos correspondientes a regresión lineal y regresión logística pueden ser útiles.\n",
    "* Asegurar el cumplimiento de los supuestos y buenas prácticas de cada modelo.\n",
    "* Utilizar las métricas de evaluación de desempeño (disponibles en las librerías especilizadas), para concluir sobre la validez de los modelos propuestos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216057b23d3cc36d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Existe algún sub-conjunto de variables socio-demográficas que explique razonablemente bien el desempeño de los estudiantes en la prueba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-94b22dd2cafa56a2",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Saber_11°_2020-2_20250912.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m a_path = \u001b[33m\"\u001b[39m\u001b[33mSaber_11°_2020-2_20250912.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m b_path = \u001b[33m\"\u001b[39m\u001b[33mSaber_11°_2020-1_20250912.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_a = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m df_b = pd.read_csv(b_path, low_memory=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      6\u001b[39m df = pd.concat([df_a, df_b], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Saber_11°_2020-2_20250912.csv'"
     ]
    }
   ],
   "source": [
    "a_path = \"Saber_11°_2020-2_20250912.csv\"\n",
    "b_path = \"Saber_11°_2020-1_20250912.csv\"\n",
    "\n",
    "df_a = pd.read_csv(a_path, low_memory=False)\n",
    "df_b = pd.read_csv(b_path, low_memory=False)\n",
    "df = pd.concat([df_a, df_b], ignore_index=True)\n",
    "\n",
    "\n",
    "cols = [\n",
    " 'ESTU_NACIONALIDAD','ESTU_GENERO','ESTU_FECHANACIMIENTO','PERIODO',\n",
    " 'ESTU_ESTUDIANTE','ESTU_PAIS_RESIDE','ESTU_TIENEETNIA',\n",
    " 'FAMI_ESTRATOVIVIENDA','FAMI_PERSONASHOGAR','FAMI_CUARTOSHOGAR',\n",
    " 'FAMI_EDUCACIONPADRE','FAMI_EDUCACIONMADRE','FAMI_TIENEINTERNET',\n",
    " 'COLE_CARACTER','PUNT_GLOBAL', 'PUNT_MATEMATICAS', 'PUNT_LECTURA_CRITICA',\n",
    " 'PUNT_C_NATURALES', 'PUNT_INGLES'\n",
    "]\n",
    "df = df[cols].copy()\n",
    "\n",
    "\n",
    "\n",
    "df[\"ESTU_FECHANACIMIENTO\"] = pd.to_datetime(df[\"ESTU_FECHANACIMIENTO\"], errors=\"coerce\", dayfirst=True)\n",
    "df[\"EDAD\"] = 2020 - df[\"ESTU_FECHANACIMIENTO\"].dt.year\n",
    "df.drop(columns=[\"ESTU_FECHANACIMIENTO\"], inplace=True)\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"O\":  \n",
    "        df[col] = df[col].fillna(\"Sin dato\")\n",
    "    else: \n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "\n",
    "cat_cols = [c for c in df.columns if df[c].dtype == \"O\" and c != \"PUNT_GLOBAL\"]\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "X = df.drop(columns=[\"PUNT_GLOBAL\"])\n",
    "y = df[\"PUNT_GLOBAL\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train) \n",
    "y_pred_lin = lin.predict(X_test)\n",
    "\n",
    "print(\"\\n Regresión Lineal \")\n",
    "print(\"R²:\", round(r2_score(y_test, y_pred_lin), 3))\n",
    "print(\"RMSE:\", round(np.sqrt(mean_squared_error(y_test, y_pred_lin)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral = y.median()\n",
    "y_bin = (y >= umbral).astype(int)\n",
    "\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X, y_bin, test_size=0.3, random_state=42)\n",
    "\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "log.fit(X_train_b, y_train_b)\n",
    "y_pred_b = log.predict(X_test_b)\n",
    "\n",
    "print(\"\\nRegresión Logística \")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_b, y_pred_b), 3))\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test_b, y_pred_b))\n",
    "\n",
    "\n",
    "plt.scatter(y_test, y_pred_lin, alpha=0.3)\n",
    "plt.xlabel(\"Puntaje Real\")\n",
    "plt.ylabel(\"Puntaje Predicho\")\n",
    "plt.title(\"Predicción vs Real - Regresión Lineal\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48c276616fb862c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fase 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb30850cd7109d78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Deberás elegir y realizar una de las dos alternativas que se encuentran a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-378e2b071d246af8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Alternativa 1: desarrollar una herramienta interactiva de análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-378e2b071d246af9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase desarrollarás, a partir de alguno de los análisis realizados, una herramienta interactiva que sea relevante en el contexto del problema, acompañada de las instrucciones necesarias para que un usuario la pueda utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-378e2b071d246af10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Seleccionar uno de los análisis previos que pueda verse enriquecido con alguna característica de interactividad.\n",
    "* Seleccionar el/los parámetro(s) que el usuario podrá cambiar.\n",
    "* Desarrollar las funciones que se deben ejecutar con cada acción del usuario.\n",
    "* Utilizar una librería especializada (ej., `ipywidgets`, `panel`, etc.) para implementar la herramienta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-378e2b071d246af11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Cuál o cuáles preguntas podrá hacerle el usuario a la herramienta y cómo aporta la respuesta al análisis?\n",
    "* ¿Qué aprendizajes clave puede explorar u obtener el usuario con esta herramienta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6b287262b7ce28bb",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implementa tu respuesta en esta celda}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8a33682f37a6fa7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Alternativa 2: registrar en bases de datos relacionales con PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8a33682f37a6fa8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En esta fase desarrollarás, a partir de alguno de los análisis realizados, un _script_ que sea relevante en el contexto del problema, acompañado de las instrucciones necesarias para que un usuario lo pueda ejecutar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8a33682f37a6fa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Pautas generales:\n",
    "\n",
    "* Cargar en una base de datos relacional (tipo SQL) el segmento de los datos sobre el cual profundizaste en tu anális, utilizando una tabla distinta para cada categoría de campos. Por ejemplo, una categoría puedes ser información del colegio; en cuyo caso, una tabla debería contener un registro único para cada colegio y todos los campos asociados.\n",
    "\n",
    "* Los campos, a excepción de los identificadores, deben existir en un única tabla.\n",
    "\n",
    "* Cada registro debe existir una única vez en su respectiva tabla.\n",
    "\n",
    "* Cada registro debe tener un identificador único en su tabla, el cual establece una relación entre tablas.\n",
    "\n",
    "* Seleccionar uno de los modelos predictivos implementados.\n",
    "\n",
    "* Crear en la base de datos relacional una tabla que contenga únicamente los identificadores del registro y la predicción de la variable de respuesta hecha por el modelo.\n",
    "\n",
    "* Desarrollar _queries_ de SQL según las siguientes indicaciones y concluir acerca de los resultados:\n",
    "    * Un _query_ que seleccione todos registros y los agregue en una única tabla. Para esto debes relacionar las tablas por su identificador, utilizando el método `JOIN`.\n",
    "    * Un _query_ que contenga el puntaje promedio de los estudiantes, agrupado por año y por colegio.\n",
    "    * Distintos _queries_ que calculen medidas de error de predicción del modelo a partir de los datos reales y las predicciones respectivas. Debes reportar el error para cada registro, el error total de los registros de entrenamiento y el error total de los registros de prueba.\n",
    "    * Haz dos _queries_ adicionales que resulten interesantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8a33682f37a6fa10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preguntas guía:\n",
    "\n",
    "* ¿Cómo aporta la segmentación de los datos en categorías de campos al manejo de los datos?\n",
    "* ¿Qué filtros y agrupaciones podemos aplicar sobre los datos con el fin de obtener información relevante?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-29052f96082e3438",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implementa tu respuesta en esta celda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32cfb4282f725e3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32cfb4282f725e3c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*  J. VanderPlas (2016) *Python Data Science Handbook: Essential Tools for Working with Data* O'Reilly Media, Inc.\n",
    "*  scikit-learn developers . (2020). Demo of DBSCAN clustering algorithm. 11 Diciembre 2020, de scikit-learn <br> https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#sphx-glr-auto-examples-cluster-plot-dbscan-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32cfb4282f725e3c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Créditos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32cfb4282f725e3c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Autores__: Camilo Hernando Gómez Castro, Alejandro Mantilla Redondo, Jose Fernando Barrera de Plaza, Diego Alejandro Cely Gómez.\n",
    "\n",
    "__Fecha última actualización__: 29/09/2022"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
